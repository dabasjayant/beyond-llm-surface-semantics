{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3520952e-2d5e-40d8-8dcc-17cacd02d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m64 packages\u001b[0m \u001b[2min 455ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 45ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m0                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install numpy pandas matplotlib tqdm ipywidgets datasets transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b687dac-a136-4457-ad1c-69b74b78b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8076dc6f-101c-46c3-b068-daa38c26af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install google google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6dcf6d-2ebb-4042-930c-3bbffbaa6b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b10d3f8-9ca3-42d3-8664-c8c58ac8146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "    \n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb79a294-75c8-4dbd-8547-a6396d49664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import base64\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Tools from Hugging Face\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74cd737-0ebb-4398-ac49-6882b4f3d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d602c7ef-e56c-4a0c-987d-75c2e5d9304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data):\n",
    "    prompt = 'Answer the following question based on the given facts, rules, and preferences. Provide a true or false answer (binary cross-entropy).\\n\\n'\n",
    "    \n",
    "    # Add facts to the prompt\n",
    "    prompt += 'Facts:\\n'\n",
    "    for fact in data['facts']:\n",
    "        prompt += f'- {fact}\\n'\n",
    "\n",
    "    # Add rules to the prompt\n",
    "    prompt += '\\nRules:\\n'\n",
    "    for rule in data['rules']:\n",
    "        prompt += f\"- {rule}\\n\"\n",
    "    \n",
    "    # Add preferences to the prompt\n",
    "    prompt += '\\nPreferences:\\n'\n",
    "    for preference in data['preferences']:\n",
    "        prompt += f'- {preference}\\n'\n",
    "    \n",
    "    # Add the question\n",
    "    prompt += f'\\nQuestion: {data['question']}\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e83a356-1584-4b30-8877-915c54da5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on the given facts, rules, and preferences. Provide a true or false answer (binary cross-entropy).\n",
      "\n",
      "Facts:\n",
      "- F1: The Coastal Protection Act requires a 30% reduction in industrial emissions by 2030.\n",
      "- F2: Senator Blackwood represents a state with significant coastal tourism.\n",
      "- F3: Senator Blackwood's campaign received substantial funding from traditional energy companies.\n",
      "- F4: Senator Blackwood has previously supported incremental environmental regulation.\n",
      "\n",
      "Rules:\n",
      "- R1: Senators typically prioritize economic interests of their major campaign donors.\n",
      "- R2: Representatives of coastal regions generally support climate protection measures affecting their constituency.\n",
      "- R3: Politicians who support incremental approaches typically oppose sweeping regulatory changes.\n",
      "\n",
      "Preferences:\n",
      "- P1: Regional economic interests take precedence over donor interests when directly conflicting.\n",
      "- P2: Historical voting patterns predict future votes unless circumstances significantly change.\n",
      "\n",
      "Question: Will Senator Blackwood vote for the Coastal Protection Act?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_data('data/politics.json')[0]\n",
    "prompt = generate_prompt(data)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3adc23ee-901f-4bf4-9dcb-0027b690557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get('GEMINI_API_KEY'),\n",
    "    )\n",
    "\n",
    "    model = 'gemini-2.5-pro-exp-03-25'\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role='user',\n",
    "            parts=[\n",
    "                types.Part.from_text(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_mime_type='text/plain',\n",
    "    )\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667b5fbd-35af-4b08-9174-14c3984e7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Analysis:**\n",
      "\n",
      "1.  **Pro-Vote Arguments (Supporting \"True\"):**\n",
      "    *   F2 (Represents coastal state) + R2 (Coastal reps support climate protection) suggests a 'Yes'.\n",
      "    *   P1 prioritizes regional interests (F2 - coastal tourism) over donor interests (F3 - energy companies), strengthening the R2 argument over the R1 argument.\n",
      "\n",
      "2.  **Anti-Vote Arguments (Supporting \"False\"):**\n",
      "    *   F3 (Energy funding) + R1 (Senators prioritize donors) suggests a 'No'. (However, P1 weakens this by prioritizing F2 over F3).\n",
      "    *   F4 (Supports incremental regulation) + R3 (Incremental supporters oppose sweeping changes) suggests a 'No'. The 30% reduction in F1 sounds like a potentially \"sweeping\" change, not incremental.\n",
      "    *   P2 (Historical patterns predict future votes) reinforces the F4+R3 argument. Blackwood's pattern is incrementalism, predicting opposition to non-incremental measures like the CPA.\n",
      "\n",
      "3.  **Conflict Resolution:** The primary conflict is between the regional interest (F2+R2, strengthened by P1) pushing for 'Yes' and the Senator's established legislative approach/ideology (F4+R3, strengthened by P2) pushing for 'No'. P2 gives significant weight to past behavior (incrementalism) as a predictor. The 30% cut described in F1 appears substantial and likely qualifies as \"sweeping\" rather than \"incremental,\" aligning with the conditions in R3. Therefore, the combination of F4, R3, and P2 provides a strong rationale for predicting a 'No' vote.\n",
      "\n",
      "**Conclusion:** The Senator's history of supporting only incremental environmental regulation (F4, R3), reinforced by the preference for historical patterns as predictors (P2), outweighs the regional interest (F2, R2, P1), especially given the potentially sweeping nature of the Act (F1).\n",
      "\n",
      "**Answer:** False"
     ]
    }
   ],
   "source": [
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1fd92-77e7-4e10-a009-a753247868a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
