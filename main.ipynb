{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3520952e-2d5e-40d8-8dcc-17cacd02d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m7 packages\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install numpy pandas matplotlib tqdm datasets transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b687dac-a136-4457-ad1c-69b74b78b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m4 packages\u001b[0m \u001b[2min 17ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --pre torch torchvision torchaudio executorch --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8076dc6f-101c-46c3-b068-daa38c26af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install google google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6dcf6d-2ebb-4042-930c-3bbffbaa6b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4988af-4bad-477d-b95a-cbf63b161d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 1.38s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                                \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2024.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --upgrade accelerate optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae91d3f-e367-42de-b911-c5f88171c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f74c92-67f3-49a3-b356-454c22b2804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2024.12.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install gptqmodel --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba762f7-646d-4c7f-989a-061ef2e67b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install tiktoken blobfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db0d5b4-44d4-4246-a05c-4f6d4601a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m8 packages\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install huggingface_hub tiktoken torchtune sentencepiece tokenizers snakeviz lm_eval==0.4.5 blobfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2631be-c184-4352-9082-bfb2ff520d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # If the import fails, this means there's nothing to remove\n",
    "    import examples\n",
    "\n",
    "    try:\n",
    "        # If the import succeeds, this means it isn't using lm_eval's module\n",
    "        import examples.models\n",
    "    except:\n",
    "        print(\n",
    "            \"Failed to import examples.models due to lm_eval conflict. Removing lm_eval examples module\"\n",
    "        )\n",
    "        import shutil\n",
    "\n",
    "        examples_path = examples.__path__[0]\n",
    "        shutil.rmtree(examples_path)\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7745986-cdf2-411b-8894-c6d575f10a26",
   "metadata": {},
   "source": [
    "## Our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843e1a4f-f2e4-4edd-9fc0-c82972a30f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "    \n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cef35357-4a91-459a-aaba-322bf196247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayantdabas/Documents/GitHub/beyond-llm-surface-semantics/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.turn_controller import TurnController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0c7de6-a302-494f-8eab-d5bcfd2fa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_path = {\n",
    "    # 'behavior': 'data/behavior.json',\n",
    "    # 'healthcare': 'data/healthcare.json',\n",
    "    # 'sports': 'data/politics.json',\n",
    "    # 'science': 'data/science.json',\n",
    "    'politics': 'data/politics.json',\n",
    "}\n",
    "\n",
    "controller = TurnController(domain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df098723-9c82-4014-b6fc-be46404cb6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running domain: politics with 10 scenarios...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "controller.run_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7037b71-8ff4-47a2-9032-f84a62d2d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.104, 'neu': 0.896, 'pos': 0.0, 'compound': -0.296}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jayantdabas/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "text = \"\"\"answer: no\n",
    "\n",
    "explanation: \n",
    "- the coastal protection act requires a 30% reduction in industrial emissions by 2030.\n",
    "- senator blackwood represents a state wi \"\"\"\n",
    "scores = sid.polarity_scores(text)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0045d0-989b-4952-acc0-04867318d4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe859d8-216a-4b37-b34f-170df7ee92f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed78c66d-48a3-4bfa-a3df-fc6d7e8d934e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jayantdabas/Documents/GitHub/beyond-llm-surface-semantics/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.builder.data_loader import DataLoader\n",
    "from src.builder.prompt_generator import PromptGenerator\n",
    "\n",
    "from src.model.inference import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86baa6f-246d-4768-bb68-27a590589f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_path = {\n",
    "    'politics': 'data/politics.json'\n",
    "}\n",
    "\n",
    "data_loader = DataLoader(domain_path)\n",
    "prompt_generator = PromptGenerator()\n",
    "\n",
    "model_inference = ModelInference()\n",
    "\n",
    "# Load data\n",
    "data = data_loader.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c9af60-5aa5-4ec9-83ac-b06b89e63bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facts:\n",
      "- The Coastal Protection Act requires a 30% reduction in industrial emissions by 2030.\n",
      "- Senator Blackwood represents a state with significant coastal tourism.\n",
      "- Senator Blackwood's campaign received substantial funding from traditional energy companies.\n",
      "- Senator Blackwood has previously supported incremental environmental regulation.\n",
      "\n",
      "Rules:\n",
      "- R1: Senators typically prioritize economic interests of their major campaign donors.\n",
      "- R2: Representatives of coastal regions generally support climate protection measures affecting their constituency.\n",
      "- R3: Politicians who support incremental approaches typically oppose sweeping regulatory changes.\n",
      "\n",
      "Preferences:\n",
      "- P1: Regional economic interests take precedence over donor interests when directly conflicting.\n",
      "- P2: Historical voting patterns predict future votes unless circumstances significantly change.\n",
      "\n",
      "Answer the below question as true or false based on the given facts, rules, and preferences. Output format should always start with \"Answer: true\" or \"Answer: false\". [Important]: We do not need explanation so do not output explanations!\n",
      "\n",
      "Question: Will Senator Blackwood vote for the Coastal Protection Act?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for domain, scenarios in data.items():\n",
    "    # For each scenario\n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        prompt = prompt_generator.generate_prompt(scenario)\n",
    "        print(prompt)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60869cfe-dbf0-4de3-84fe-203212cf25c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: true\n",
      "explanation:\n",
      "the coastal protection act requires a 30% reduction in industrial emissions by 2030.\n",
      "senator blackwood represents a state with significant coastal tourism.\n",
      "senator blackwood's campaign received substantial funding from traditional energy companies.\n",
      "senator black\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8358d4c3-43f2-4597-84c3-bb9c2a5050e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: true\n",
      "explanation: senator blackwood represents a state with significant coastal tourism. senator blackwood's campaign received substantial funding from traditional energy companies. senator blackwood has previously supported incremental environmental regulation. therefore, we can conclude that senator blackwood will\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "752ff340-b31f-4ad7-ae34-32cd7f37f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: true\n",
      "\n",
      "explanation: the coastal protection act requires a 30% reduction in industrial emissions by 2030. senator blackwood represents a state with significant coastal tourism. senator blackwood's campaign received substantial funding from traditional energy companies. senator black\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd003755-c79e-43ff-b91a-e2884aa9b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: true\n",
      "\n",
      "explanation: senator blackwood represents a state with significant coastal tourism. senator blackwood's campaign received substantial funding from traditional energy companies. senator blackwood has previously supported incremental environmental regulation. senator blackwood's campaign received substantial funding from traditional\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab07d5b-1718-4a5e-b4f4-9cd5b31f1e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: true\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f218c0-ec3c-42ed-842f-ddc89d93d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: false\n",
      "explanation: \n",
      "the coastal protection act requires a 30% reduction in industrial emissions by 2030. senator blackwood represents a state with significant coastal tourism. senator blackwood's campaign received substantial funding from traditional energy companies. senator\n"
     ]
    }
   ],
   "source": [
    "print(model_inference.chat(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17294f-25fb-4710-838d-e73defe70748",
   "metadata": {},
   "source": [
    "## Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b10d3f8-9ca3-42d3-8664-c8c58ac8146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "    \n",
    "load_dotenv(dotenv_path='.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb79a294-75c8-4dbd-8547-a6396d49664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import base64\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Tools from Hugging Face\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74cd737-0ebb-4398-ac49-6882b4f3d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602c7ef-e56c-4a0c-987d-75c2e5d9304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data):\n",
    "    prompt = 'Answer the following question based on the given facts, rules, and preferences. Provide a true or false answer (binary cross-entropy) for each round, and make sure to take the information of initial setting and past rounds into consideration.\\n\\n'\n",
    "    \n",
    "    # Add facts to the prompt\n",
    "    prompt += 'Facts:\\n'\n",
    "    for fact in data['facts']:\n",
    "        prompt += f'- {fact}\\n'\n",
    "\n",
    "    # Add rules to the prompt\n",
    "    prompt += '\\nRules:\\n'\n",
    "    for rule in data['rules']:\n",
    "        prompt += f\"- {rule}\\n\"\n",
    "    \n",
    "    # Add preferences to the prompt\n",
    "    prompt += '\\nPreferences:\\n'\n",
    "    for preference in data['preferences']:\n",
    "        prompt += f'- {preference}\\n'\n",
    "    \n",
    "    # Add the question\n",
    "    prompt += f'\\nQuestion: {data['question']}\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e83a356-1584-4b30-8877-915c54da5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question based on the given facts, rules, and preferences. Provide a true or false answer (binary cross-entropy).\n",
      "\n",
      "Facts:\n",
      "- F1: The Coastal Protection Act requires a 30% reduction in industrial emissions by 2030.\n",
      "- F2: Senator Blackwood represents a state with significant coastal tourism.\n",
      "- F3: Senator Blackwood's campaign received substantial funding from traditional energy companies.\n",
      "- F4: Senator Blackwood has previously supported incremental environmental regulation.\n",
      "\n",
      "Rules:\n",
      "- R1: Senators typically prioritize economic interests of their major campaign donors.\n",
      "- R2: Representatives of coastal regions generally support climate protection measures affecting their constituency.\n",
      "- R3: Politicians who support incremental approaches typically oppose sweeping regulatory changes.\n",
      "\n",
      "Preferences:\n",
      "- P1: Regional economic interests take precedence over donor interests when directly conflicting.\n",
      "- P2: Historical voting patterns predict future votes unless circumstances significantly change.\n",
      "\n",
      "Question: Will Senator Blackwood vote for the Coastal Protection Act?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_data('data/politics.json')[0]\n",
    "prompt = generate_prompt(data)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc23ee-901f-4bf4-9dcb-0027b690557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get('GEMINI_API_KEY'),\n",
    "    )\n",
    "\n",
    "    model = 'gemini-2.5-pro-exp-03-25'\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role='user',\n",
    "            parts=[\n",
    "                types.Part.from_text(text=prompt),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        response_mime_type='text/plain',\n",
    "    )\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667b5fbd-35af-4b08-9174-14c3984e7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Analysis:**\n",
      "\n",
      "1.  **Pro-Vote Arguments (Supporting \"True\"):**\n",
      "    *   F2 (Represents coastal state) + R2 (Coastal reps support climate protection) suggests a 'Yes'.\n",
      "    *   P1 prioritizes regional interests (F2 - coastal tourism) over donor interests (F3 - energy companies), strengthening the R2 argument over the R1 argument.\n",
      "\n",
      "2.  **Anti-Vote Arguments (Supporting \"False\"):**\n",
      "    *   F3 (Energy funding) + R1 (Senators prioritize donors) suggests a 'No'. (However, P1 weakens this by prioritizing F2 over F3).\n",
      "    *   F4 (Supports incremental regulation) + R3 (Incremental supporters oppose sweeping changes) suggests a 'No'. The 30% reduction in F1 sounds like a potentially \"sweeping\" change, not incremental.\n",
      "    *   P2 (Historical patterns predict future votes) reinforces the F4+R3 argument. Blackwood's pattern is incrementalism, predicting opposition to non-incremental measures like the CPA.\n",
      "\n",
      "3.  **Conflict Resolution:** The primary conflict is between the regional interest (F2+R2, strengthened by P1) pushing for 'Yes' and the Senator's established legislative approach/ideology (F4+R3, strengthened by P2) pushing for 'No'. P2 gives significant weight to past behavior (incrementalism) as a predictor. The 30% cut described in F1 appears substantial and likely qualifies as \"sweeping\" rather than \"incremental,\" aligning with the conditions in R3. Therefore, the combination of F4, R3, and P2 provides a strong rationale for predicting a 'No' vote.\n",
      "\n",
      "**Conclusion:** The Senator's history of supporting only incremental environmental regulation (F4, R3), reinforced by the preference for historical patterns as predictors (P2), outweighs the regional interest (F2, R2, P1), especially given the potentially sweeping nature of the Act (F1).\n",
      "\n",
      "**Answer:** False"
     ]
    }
   ],
   "source": [
    "generate_response(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
